{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Review-Synthetic-Data-V4.1_addedFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean_test_allFP.csv', 'clean_test_greedyFP.csv', 'clean_test_leakFP.csv', 'clean_test_suicidalFP.csv', 'clean_train.csv', 'LsMa', 'no_duplicates', 'old_no_duplicates']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Input data files are available in the \"./input_data/\" directory.\n",
    "import os\n",
    "print(os.listdir(\"./input_data/final\"))\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas.tools.plotting import table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(df):    \n",
    "    # label data\n",
    "    df['LABEL'] = 0\n",
    "    df.loc[df['CATEGORY'] == '1 0 0 0', 'LABEL'] = 0\n",
    "    df.loc[df['CATEGORY'] != '1 0 0 0', 'LABEL'] = 1\n",
    "    \n",
    "def preprocess(df):\n",
    "    n_most_common_words = 1000 #8000\n",
    "    max_len = 130\n",
    "\n",
    "    # Class Tokenizer - This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary)\n",
    "    # tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer = Tokenizer(num_words=n_most_common_words, lower=False)\n",
    "\n",
    "    # fit_on_texts - Updates internal vocabulary based on a list of texts. In the case where texts contains lists, we assume each entry of the lists to be a token.\n",
    "    # tokenizer.fit_on_texts(increased_vul['OPCODE'].values)\n",
    "    tokenizer.fit_on_texts(df['OPCODE'].values)\n",
    "\n",
    "    # # Transforms each text in texts in a sequence of integers.\n",
    "    sequences = tokenizer.texts_to_sequences(df['OPCODE'].values)\n",
    "    # sequences = tokenizer.texts_to_sequences(tt)\n",
    "\n",
    "    #Find number of unique words/tokens\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "    #pad sequences with zeros in front to make them all maxlen\n",
    "    X = pad_sequences(sequences, maxlen=max_len)\n",
    "    return X\n",
    "\n",
    "def dftoXY(df):\n",
    "    # Save test X and y\n",
    "    X_test = preprocess(df)\n",
    "    # label data\n",
    "    label(df)\n",
    "#     df['LABEL'] = 0\n",
    "#     df.loc[df['CATEGORY'] == '1 0 0 0', 'LABEL'] = 0\n",
    "#     df.loc[df['CATEGORY'] != '1 0 0 0', 'LABEL'] = 1\n",
    "    print(pd.value_counts(df['LABEL']))\n",
    "    y_test = to_categorical(df['LABEL'], num_classes=2)\n",
    "    return X_test, y_test    \n",
    "\n",
    "def XandY(posdf, negdf=None):\n",
    "    dfset = pd.concat([posdf, negdf])\n",
    "    dfset = dfset.sample(frac=1, random_state=39, replace=False)\n",
    "\n",
    "    dfset['LABEL'] = 0\n",
    "\n",
    "    #One-hot encode the lab\n",
    "    dfset.loc[dfset['CATEGORY'] == '1 0 0 0', 'LABEL'] = 0\n",
    "    dfset.loc[dfset['CATEGORY'] != '1 0 0 0', 'LABEL'] = 1\n",
    "    # df_train.head()\n",
    "\n",
    "    X, y = dftoXY(dfset)\n",
    "\n",
    "    print('Shape of X: {}'.format(X.shape))\n",
    "\n",
    "    # for sm.fit_sample\n",
    "    y_labels = np.expand_dims(np.array(np.argmax(y, axis=1)), axis=1)\n",
    "    print('Shape of y: {}'.format(y_labels.shape))\n",
    "\n",
    "    return X, y_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>OPCODE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x219f4ee903f78e78773e5d1e3520cfd507485bc6</td>\n",
       "      <td>60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...</td>\n",
       "      <td>1 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x560ed796aa8d23411b94b9d047ecdda39d4fcdeb</td>\n",
       "      <td>60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...</td>\n",
       "      <td>1 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xe726f97ff3c63dd71c1520c102adc39d1a2693ea</td>\n",
       "      <td>60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...</td>\n",
       "      <td>1 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x8ebac490495958b3804bb079e259340f0f53b69c</td>\n",
       "      <td>60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...</td>\n",
       "      <td>1 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x190700d69031db6b072a30577f9b3dbc53a320a1</td>\n",
       "      <td>60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...</td>\n",
       "      <td>1 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ADDRESS  \\\n",
       "0  0x219f4ee903f78e78773e5d1e3520cfd507485bc6   \n",
       "1  0x560ed796aa8d23411b94b9d047ecdda39d4fcdeb   \n",
       "2  0xe726f97ff3c63dd71c1520c102adc39d1a2693ea   \n",
       "3  0x8ebac490495958b3804bb079e259340f0f53b69c   \n",
       "4  0x190700d69031db6b072a30577f9b3dbc53a320a1   \n",
       "\n",
       "                                              OPCODE CATEGORY  \n",
       "0  60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...  1 0 0 0  \n",
       "1  60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...  1 0 0 0  \n",
       "2  60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...  1 0 0 0  \n",
       "3  60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...  1 0 0 0  \n",
       "4  60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...  1 0 0 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and reading csv input data \n",
    "# dataset = 'results_merged_12-10-2018_noTP.csv'\n",
    "# dataset = 'results_merged_12-10-2018_dataset1_greedy.csv'\n",
    "# dataset = 'results_fixed_first100k.csv'\n",
    "dataset = 'clean_train.csv'\n",
    "data = pd.read_csv('./input_data/final/'+dataset, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.iloc[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 0 0 0    884273\n",
       "0 0 0 1      5801\n",
       "0 0 1 0      1461\n",
       "0 1 0 0      1207\n",
       "0 1 1 0       171\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['CATEGORY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "count_classes = pd.value_counts(data['CATEGORY'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Vulnerability Class Histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.show()\n",
    "# fig.savefig('./figures/clean_train_unbalanced_distr.png', dpi=300) #, bbox_inches='tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing data into vulnerable and non-vulnerable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffled = data.reindex(np.random.permutation(data.index))\n",
    "shuffled = data\n",
    "\n",
    "# shuffled = data\n",
    "n = shuffled[shuffled['CATEGORY'] == '1 0 0 0'] # no vulnerabilities\n",
    "s = shuffled[shuffled['CATEGORY'] == '0 1 0 0'] # suicidal\n",
    "p = shuffled[shuffled['CATEGORY'] == '0 0 1 0'] # prodigal\n",
    "g = shuffled[shuffled['CATEGORY'] == '0 0 0 1'] # greedy\n",
    "sp = shuffled[shuffled['CATEGORY'] == '0 1 1 0'] # suicidal and prodigal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot two class unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "concated = pd.concat([n,s,p,g,sp], ignore_index=True)\n",
    "\n",
    "#Shuffle the dataset\n",
    "concated = concated.reindex(np.random.permutation(concated.index))\n",
    "concated['LABEL'] = 0\n",
    "\n",
    "#One-hot encode the lab\n",
    "concated.loc[concated['CATEGORY'] == '1 0 0 0', 'LABEL'] = 0\n",
    "concated.loc[concated['CATEGORY'] != '1 0 0 0', 'LABEL'] = 1\n",
    "\n",
    "import seaborn as sns\n",
    "fig = plt.figure()\n",
    "# colors = [\"#0101DF\", \"#DF0101\"]\n",
    "colors = [\"#A1CAF1\", \"#E30022\"]\n",
    "\n",
    "sns.countplot('LABEL', data=concated, palette=colors)\n",
    "plt.title('Class Distributions \\n (0 = Not vulnerable || 1 = Vulnerable)', fontsize=14)\n",
    "fig.set_size_inches(8, 8)\n",
    "# fig.savefig('./figures/clean_train_unbalanced2class.png', dpi=300) #, bbox_inches='tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing data into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n"
     ]
    }
   ],
   "source": [
    "# ========== set of vul contracts ========== \n",
    "# shuffle positives dataset\n",
    "positives = pd.concat([s,p,g,sp])\n",
    "positives_shuf = positives.sample(frac=1, random_state=39, replace=False)\n",
    "print(len(positives_shuf))\n",
    "\n",
    "# split positives dataset into train, val, and test\n",
    "proportion_train = 0.64 #0.7 \n",
    "proportion_val = 0.16 #0.1 \n",
    "proportion_test = 0.2 #0.20\n",
    "\n",
    "num_pos_train = round(len(positives_shuf) * proportion_train)\n",
    "num_pos_val = round(len(positives_shuf) * proportion_val)\n",
    "\n",
    "pos_train = positives_shuf.iloc[0:num_pos_train] \n",
    "pos_val = positives_shuf.iloc[num_pos_train:(num_pos_train+num_pos_val)]\n",
    "pos_test = positives_shuf.iloc[(num_pos_train+num_pos_val):]\n",
    "\n",
    "# print(len(pos_train))\n",
    "# print(len(pos_val))\n",
    "# print(len(pos_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== set of non-vul contracts ========== \n",
    "# # shuffle set n\n",
    "n_shuf = n.sample(frac=1, random_state=39, replace=False)\n",
    "\n",
    "n_shuf['FP'] = 0\n",
    "# set number of samples in each set\n",
    "num_neg_train = 9000 #30000 #11000\n",
    "num_neg_val = round(((num_neg_train)/proportion_train)*proportion_val)\n",
    "num_neg_test = round(((num_neg_train)/proportion_train)*proportion_test)\n",
    "\n",
    "neg_train = n_shuf.iloc[0:num_neg_train]\n",
    "neg_val = n_shuf.iloc[num_neg_train:(num_neg_train+num_neg_val)]\n",
    "neg_test = n_shuf.iloc[(num_neg_train+num_neg_val):(num_neg_train+num_neg_val+num_neg_test)]\n",
    "\n",
    "# neg_notused = n_shuf.iloc[(num_neg_train+num_neg_val+num_neg_test):]\n",
    "# print(\"Number of negative samples not used: \", len(neg_notused))\n",
    "\n",
    "# print(len(neg_train))\n",
    "# print(len(neg_val))\n",
    "# print(len(neg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Leak FPs:  177\n",
      "Total Number of Suicidal FPs:  72\n",
      "Total Number of Greedy FPs:  202\n",
      "Number of Leak FPs for Training:  141\n",
      "Number of Leak FPs for Test:  36\n",
      "Number of Suicidal FPs for Training:  59\n",
      "Number of Suicidal FPs for Test:  13\n",
      "Number of Lock FPs for Training:  148\n",
      "Number of Lock FPs for Test:  54\n",
      "Number of FPs:  348\n"
     ]
    }
   ],
   "source": [
    "# ========== adding FPs into non-vul training set ========== \n",
    "# FPs = \"clean_test_allFP_noDups.csv\"\n",
    "# allFPs = pd.read_csv('./input_data/final/no_duplicates/'+ FPs, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "# all_testset = 'clean_test_allFP_noDups.csv'\n",
    "leakFP = 'clean_test_leakFP_noDups.csv'\n",
    "suicidalFP = 'clean_test_suicidalFP_noDups.csv'\n",
    "greedyFP = 'clean_test_greedyFP_noDups.csv'\n",
    "\n",
    "leakFPs = pd.read_csv('./input_data/final/no_duplicates/'+leakFP, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "print(\"Total Number of Leak FPs: \", len(leakFPs))\n",
    "suicidalFPs = pd.read_csv('./input_data/final/no_duplicates/'+suicidalFP, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "print(\"Total Number of Suicidal FPs: \", len(suicidalFPs))\n",
    "greedyFPs = pd.read_csv('./input_data/final/no_duplicates/'+greedyFP, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "print(\"Total Number of Greedy FPs: \", len(greedyFPs))\n",
    "\n",
    "# Split FPs into training and test set\n",
    "FPtrain_frac = 0.8\n",
    "def FPsplit(df, train_frac):\n",
    "    msk = np.random.rand(len(df)) <= train_frac\n",
    "    train_df = df[msk]\n",
    "    test_df = df[~msk]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_leakFPs, test_leakFPs = FPsplit(leakFPs, FPtrain_frac)\n",
    "print(\"Number of Leak FPs for Training: \", len(train_leakFPs))\n",
    "print(\"Number of Leak FPs for Test: \", len(test_leakFPs))\n",
    "\n",
    "train_suicidalFPs, test_suicidalFPs = FPsplit(suicidalFPs, FPtrain_frac)\n",
    "print(\"Number of Suicidal FPs for Training: \", len(train_suicidalFPs))\n",
    "print(\"Number of Suicidal FPs for Test: \", len(test_suicidalFPs))\n",
    "\n",
    "train_lockFPs, test_lockFPs = FPsplit(greedyFPs, FPtrain_frac)\n",
    "print(\"Number of Lock FPs for Training: \", len(train_lockFPs))\n",
    "print(\"Number of Lock FPs for Test: \", len(test_lockFPs))\n",
    "\n",
    "trainFPs = pd.concat([train_leakFPs, train_suicidalFPs, train_lockFPs])\n",
    "\n",
    "# add column to classify FPs and non-FPs\n",
    "trainFPs['FP'] = 1\n",
    "\n",
    "numFPs = len(trainFPs)\n",
    "# print(\"Number of Original Negatives: \", len(neg_train))\n",
    "print(\"Number of FPs: \", numFPs) #allFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>FP</th>\n",
       "      <th>OPCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7356</th>\n",
       "      <td>0xd52351f24702f2544a455a64c4d00c956a323614</td>\n",
       "      <td>1 0 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59163</th>\n",
       "      <td>0x9ebe9f86af71452d881875be50df5bf8180ea06a</td>\n",
       "      <td>1 0 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60 60 52 36 15 61 57 60 60 0a 60 35 04 63 81 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804669</th>\n",
       "      <td>0xa3aea63ace61db42e4b63328234688c857f0d36d</td>\n",
       "      <td>1 0 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60 60 52 60 60 0a 60 35 04 63 81 14 60 57 5b 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613041</th>\n",
       "      <td>0x36a8759350cc9ef5216d2d2aa06ef95f93854611</td>\n",
       "      <td>1 0 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801456</th>\n",
       "      <td>0xb3d8c02a09156e7a431fa3ecca058f7952ae8aae</td>\n",
       "      <td>1 0 0 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ADDRESS CATEGORY  FP  \\\n",
       "7356    0xd52351f24702f2544a455a64c4d00c956a323614  1 0 0 0 NaN   \n",
       "59163   0x9ebe9f86af71452d881875be50df5bf8180ea06a  1 0 0 0 NaN   \n",
       "804669  0xa3aea63ace61db42e4b63328234688c857f0d36d  1 0 0 0 NaN   \n",
       "613041  0x36a8759350cc9ef5216d2d2aa06ef95f93854611  1 0 0 0 NaN   \n",
       "801456  0xb3d8c02a09156e7a431fa3ecca058f7952ae8aae  1 0 0 0 NaN   \n",
       "\n",
       "                                                   OPCODE  \n",
       "7356    60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...  \n",
       "59163   60 60 52 36 15 61 57 60 60 0a 60 35 04 63 81 1...  \n",
       "804669  60 60 52 60 60 0a 60 35 04 63 81 14 60 57 5b 6...  \n",
       "613041  60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...  \n",
       "801456  60 60 52 36 15 61 57 60 35 7c 90 04 63 16 80 6...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negval_addFP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 unique tokens.\n",
      "Found 150 unique tokens.\n",
      "Found 150 unique tokens.\n",
      "Shape of X: (9223, 130)\n",
      "Shape of y: (9223, 1)\n",
      "Shape of X: (2306, 130)\n",
      "Shape of y: (2306, 1)\n",
      "Shape of X: (2881, 130)\n",
      "Shape of y: (2881, 1)\n",
      "Number transactions X_negtrain dataset:  (9223, 130)\n",
      "Number transactions y_negtrain dataset:  (9223, 1)\n",
      "Before OverSampling, train counts of label '1': [223]\n",
      "Before OverSampling, train counts of label '0': [9000]\n",
      "Before OverSampling, val counts of label '1': [56]\n",
      "Before OverSampling, val counts of label '0': [2250]\n",
      "Before OverSampling, test counts of label '1': [69]\n",
      "Before OverSampling, test counts of label '0': [2812]\n"
     ]
    }
   ],
   "source": [
    "# set number of samples in each set\n",
    "numtrainFPs = round(numFPs*proportion_train)\n",
    "numvalFPs = round(numFPs*proportion_val)\n",
    "numtestFPs = numFPs - numtrainFPs - numvalFPs\n",
    "\n",
    "FP_train = trainFPs.iloc[0:numtrainFPs]\n",
    "FP_val = trainFPs.iloc[numtrainFPs:(numtrainFPs+numvalFPs)]\n",
    "FP_test = trainFPs.iloc[(numtrainFPs+numvalFPs):(numtrainFPs+numvalFPs+numtestFPs)]\n",
    "\n",
    "# Concatenate dfs\n",
    "negtrain_addFP = pd.concat([neg_train, FP_train])\n",
    "negval_addFP = pd.concat([neg_val, FP_val])\n",
    "negtest_addFP = pd.concat([neg_test, FP_test])\n",
    "# Shuffle df\n",
    "negtrain_addFP = negtrain_addFP.sample(frac=1, random_state=39, replace=False)\n",
    "negval_addFP = negval_addFP.sample(frac=1, random_state=39, replace=False)\n",
    "negtest_addFP = negtest_addFP.sample(frac=1, random_state=39, replace=False)\n",
    "# Processing X and y\n",
    "Xnegtrain_addFP = preprocess(negtrain_addFP)\n",
    "ynegtrain_addFP = to_categorical(negtrain_addFP['FP'], num_classes=2)\n",
    "Xnegval_addFP = preprocess(negval_addFP)\n",
    "ynegval_addFP = to_categorical(negval_addFP['FP'], num_classes=2)\n",
    "Xnegtest_addFP = preprocess(negtest_addFP)\n",
    "ynegtest_addFP = to_categorical(negtest_addFP['FP'], num_classes=2)\n",
    "# for sm.fit_sample\n",
    "ynegtrain_addFP_labels = np.expand_dims(np.array(np.argmax(ynegtrain_addFP, axis=1)), axis=1)\n",
    "print('Shape of X: {}'.format(Xnegtrain_addFP.shape))\n",
    "print('Shape of y: {}'.format(ynegtrain_addFP_labels.shape))\n",
    "ynegval_addFP_labels = np.expand_dims(np.array(np.argmax(ynegval_addFP, axis=1)), axis=1)\n",
    "print('Shape of X: {}'.format(Xnegval_addFP.shape))\n",
    "print('Shape of y: {}'.format(ynegval_addFP_labels.shape))\n",
    "ynegtest_addFP_labels = np.expand_dims(np.array(np.argmax(ynegtest_addFP, axis=1)), axis=1)\n",
    "print('Shape of X: {}'.format(Xnegtest_addFP.shape))\n",
    "print('Shape of y: {}'.format(ynegtest_addFP_labels.shape))\n",
    "\n",
    "# Prepare train set \n",
    "# Xneg_train, ynegtrain_labels = XandY(neg_train, allFPs, label='FP')\n",
    "print(\"Number transactions X_negtrain dataset: \", Xnegtrain_addFP.shape)\n",
    "print(\"Number transactions y_negtrain dataset: \", ynegtrain_addFP_labels.shape)\n",
    "print(\"Before OverSampling, train counts of label '1': {}\".format(sum(ynegtrain_addFP_labels==1)))\n",
    "print(\"Before OverSampling, train counts of label '0': {}\".format(sum(ynegtrain_addFP_labels==0)))\n",
    "print(\"Before OverSampling, val counts of label '1': {}\".format(sum(ynegval_addFP_labels==1)))\n",
    "print(\"Before OverSampling, val counts of label '0': {}\".format(sum(ynegval_addFP_labels==0)))\n",
    "print(\"Before OverSampling, test counts of label '1': {}\".format(sum(ynegtest_addFP_labels==1)))\n",
    "print(\"Before OverSampling, test counts of label '0': {}\".format(sum(ynegtest_addFP_labels==0)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Concatenate dfs\n",
    "neg_addFP = pd.concat([neg_train, trainFPs])\n",
    "# Shuffle df\n",
    "neg_addFP = neg_addFP.sample(frac=1, random_state=39, replace=False)\n",
    "# Processing X and y\n",
    "Xneg_addFP = preprocess(neg_addFP)\n",
    "yneg_addFP = to_categorical(neg_addFP['FP'], num_classes=2)\n",
    "# for sm.fit_sample\n",
    "yneg_addFP_labels = np.expand_dims(np.array(np.argmax(yneg_addFP, axis=1)), axis=1)\n",
    "print('Shape of X: {}'.format(Xneg_addFP.shape))\n",
    "print('Shape of y: {}'.format(yneg_addFP_labels.shape))\n",
    "\n",
    "# Prepare train set \n",
    "# Xneg_train, ynegtrain_labels = XandY(neg_train, allFPs, label='FP')\n",
    "print(\"Number transactions X_neg dataset: \", Xneg_addFP.shape)\n",
    "print(\"Number transactions y_neg dataset: \", yneg_addFP_labels.shape)\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(yneg_addFP_labels==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {}\".format(sum(yneg_addFP_labels==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE(ratio=0.35, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (12150, 130)\n",
      "After OverSampling, the shape of train_y: (12150,)\n",
      "After OverSampling, the shape of val_X: (3037, 130)\n",
      "After OverSampling, the shape of val_y: (3037,)\n",
      "After OverSampling, the shape of test_X: (3796, 130)\n",
      "After OverSampling, the shape of test_y: (3796,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesley/miniconda3/envs/deeplearn_CE7454/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/wesley/miniconda3/envs/deeplearn_CE7454/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/wesley/miniconda3/envs/deeplearn_CE7454/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "Xnegtrain_res, ynegtrain_res = smt.fit_sample(Xnegtrain_addFP, ynegtrain_addFP_labels.ravel())\n",
    "Xnegval_res, ynegval_res = smt.fit_sample(Xnegval_addFP, ynegval_addFP_labels.ravel())\n",
    "Xnegtest_res, ynegtest_res = smt.fit_sample(Xnegtest_addFP, ynegtest_addFP_labels.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(Xnegtrain_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {}'.format(ynegtrain_res.shape))\n",
    "print('After OverSampling, the shape of val_X: {}'.format(Xnegval_res.shape))\n",
    "print('After OverSampling, the shape of val_y: {}'.format(ynegval_res.shape))\n",
    "print('After OverSampling, the shape of test_X: {}'.format(Xnegtest_res.shape))\n",
    "print('After OverSampling, the shape of test_y: {}'.format(ynegtest_res.shape))\n",
    "\n",
    "# change all neg labels to zero\n",
    "ynegtrain_res = np.zeros(len(ynegtrain_res))\n",
    "ynegval_res = np.zeros(len(ynegval_res))\n",
    "ynegtest_res = np.zeros(len(ynegtest_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_resampledneg = ynegtrain_res.shape[0]\n",
    "num_resampledneg_val = round(((num_resampledneg)/proportion_train)*proportion_val)\n",
    "num_resampledneg_test = round(((num_resampledneg)/proportion_train)*proportion_test)\n",
    "\n",
    "neg_val = n_shuf.iloc[num_neg_train:(num_neg_train+num_resampledneg_val)]\n",
    "neg_test = n_shuf.iloc[(num_neg_train+num_resampledneg_val):(num_neg_train+num_resampledneg_val+num_resampledneg_test)]\n",
    "\n",
    "# neg_notused = n_shuf.iloc[(num_neg_train+num_resampledneg_val+num_resampledneg_test):]\n",
    "# print(\"Number of negative samples not used: \", len(neg_notused))\n",
    "\n",
    "print(\"Number of negatives in validation dataset (16% of negtrain_addFP): \", len(neg_val))\n",
    "print(\"Number of negatives in test dataset (35% of negtrain_addFP): \", len(neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 unique tokens.\n",
      "1    5530\n",
      "Name: LABEL, dtype: int64\n",
      "Shape of X: (5530, 130)\n",
      "Shape of y: (5530, 1)\n",
      "Found 150 unique tokens.\n",
      "1    1382\n",
      "Name: LABEL, dtype: int64\n",
      "Shape of X: (1382, 130)\n",
      "Shape of y: (1382, 1)\n",
      "Found 150 unique tokens.\n",
      "1    1728\n",
      "Name: LABEL, dtype: int64\n",
      "Shape of X: (1728, 130)\n",
      "Shape of y: (1728, 1)\n"
     ]
    }
   ],
   "source": [
    "def arrayXandY(Xarray1, Xarray2, yarray1, yarray2):\n",
    "    X = np.concatenate((Xarray1, Xarray2),axis=0)\n",
    "    yarray2 = np.expand_dims(np.array(yarray2), axis=1)\n",
    "    y_labels = np.concatenate((yarray1, yarray2),axis=0)\n",
    "    \n",
    "    return X, y_labels\n",
    "\n",
    "# Prepare train set \n",
    "# X_train, ytrain_labels = XandY(pos_train, neg_train)\n",
    "Xpos_train, ypostrain_labels = XandY(pos_train)\n",
    "X_train, ytrain_labels = arrayXandY(Xpos_train, Xnegtrain_res, ypostrain_labels, ynegtrain_res)\n",
    "\n",
    "# Prepare validation set \n",
    "Xpos_val, yposval_labels = XandY(pos_val)\n",
    "X_val, yval_labels = arrayXandY(Xpos_val, Xnegval_res, yposval_labels, ynegval_res)\n",
    "\n",
    "# Prepare test set \n",
    "Xpos_test, ypostest_labels = XandY(pos_test)\n",
    "X_test, ytest_labels = arrayXandY(Xpos_test, Xnegtest_res, ypostest_labels, ynegtest_res)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# shuffle train set\n",
    "X_train, ytrain_labels = shuffle(X_train, ytrain_labels, random_state=39)\n",
    "X_val, yval_labels = shuffle(X_val, yval_labels, random_state=39)\n",
    "X_test, ytest_labels = shuffle(X_test, ytest_labels, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (17680, 130)\n",
      "Number transactions y_train dataset:  (17680, 1)\n",
      "Number transactions X_val dataset:  (4419, 130)\n",
      "Number transactions y_val dataset:  (4419, 1)\n",
      "Number transactions X_test dataset:  (5524, 130)\n",
      "Number transactions y_test dataset:  (5524, 1)\n",
      "Before OverSampling, counts of label '1': [5530]\n",
      "Before OverSampling, counts of label '0': [12150]\n",
      "Before OverSampling, counts of label '1': [1382]\n",
      "Before OverSampling, counts of label '0': [3037]\n",
      "Before OverSampling, counts of label '1': [1728]\n",
      "Before OverSampling, counts of label '0': [3796] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", ytrain_labels.shape)\n",
    "print(\"Number transactions X_val dataset: \", X_val.shape)\n",
    "print(\"Number transactions y_val dataset: \", yval_labels.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", ytest_labels.shape)\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(ytrain_labels==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {}\".format(sum(ytrain_labels==0)))\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(yval_labels==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {}\".format(sum(yval_labels==0)))\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(ytest_labels==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(ytest_labels==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ Resample ============ \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=39)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, ytrain_labels.ravel())\n",
    "X_val_res, y_val_res = sm.fit_sample(X_val, yval_labels.ravel())\n",
    "X_test_res, y_test_res = sm.fit_sample(X_test, ytest_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (24300, 130)\n",
      "After OverSampling, the shape of train_y: (24300,)\n",
      "After OverSampling, the shape of val_X: (6074, 130)\n",
      "After OverSampling, the shape of val_y: (6074,)\n",
      "After OverSampling, the shape of test_X: (7592, 130)\n",
      "After OverSampling, the shape of test_y: (7592,) \n",
      "\n",
      "After OverSampling, counts of train label '1': 12150\n",
      "After OverSampling, counts of train label '0': 12150\n",
      "After OverSampling, counts of val label '1': 3037\n",
      "After OverSampling, counts of val label '0': 3037\n",
      "After OverSampling, counts of test label '1': 3796\n",
      "After OverSampling, counts of test label '0': 3796\n"
     ]
    }
   ],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {}'.format(y_train_res.shape))\n",
    "print('After OverSampling, the shape of val_X: {}'.format(X_val_res.shape))\n",
    "print('After OverSampling, the shape of val_y: {}'.format(y_val_res.shape))\n",
    "print('After OverSampling, the shape of test_X: {}'.format(X_test_res.shape))\n",
    "print('After OverSampling, the shape of test_y: {} \\n'.format(y_test_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of train label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of train label '0': {}\".format(sum(y_train_res==0)))\n",
    "print(\"After OverSampling, counts of val label '1': {}\".format(sum(y_val_res==1)))\n",
    "print(\"After OverSampling, counts of val label '0': {}\".format(sum(y_val_res==0)))\n",
    "print(\"After OverSampling, counts of test label '1': {}\".format(sum(y_test_res==1)))\n",
    "print(\"After OverSampling, counts of test label '0': {}\".format(sum(y_test_res==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot two class balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_dataset = np.concatenate((y_train_res,y_val_res,y_test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure()\n",
    "colors = [\"#A1CAF1\", \"#E30022\"]\n",
    "\n",
    "sns.countplot(0, data=pd.DataFrame(entire_dataset), palette=colors)\n",
    "plt.title('Class Distributions \\n (0 = Not vulnerable || 1 = Vulnerable)', fontsize=14)\n",
    "fig.set_size_inches(8, 8)\n",
    "# fig.savefig('./figures/clean_train_unbalanced2class.png', dpi=300) #, bbox_inches='tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "epochs = 50 #100\n",
    "emb_dim = 128 #150\n",
    "batch_size = 256 #512   \n",
    "# labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear model\n",
    "import keras\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((24300, 130), (24300, 2), (6074, 130), (6074, 2), (7592, 130), (7592, 2))\n"
     ]
    }
   ],
   "source": [
    "# Convert format for training  \n",
    "ytrainres_cat = to_categorical(y_train_res, num_classes=2)\n",
    "yvalres_cat = to_categorical(y_val_res, num_classes=2)\n",
    "ytestres_cat = to_categorical(y_test_res, num_classes=2)\n",
    "\n",
    "print((X_train_res.shape, ytrainres_cat.shape, X_val_res.shape, yvalres_cat.shape, X_test_res.shape, ytestres_cat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 130, 128)          128000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 130, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                9280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 137,314\n",
      "Trainable params: 137,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19800 samples, validate on 4950 samples\n",
      "Epoch 1/50\n",
      "19800/19800 [==============================] - 19s 941us/step - loss: 0.4504 - acc: 0.8975 - val_loss: 0.5998 - val_acc: 0.7426\n",
      "Epoch 2/50\n",
      "19800/19800 [==============================] - 17s 866us/step - loss: 0.1647 - acc: 0.9541 - val_loss: 0.6985 - val_acc: 0.6954\n",
      "Epoch 3/50\n",
      "19800/19800 [==============================] - 17s 872us/step - loss: 0.1131 - acc: 0.9636 - val_loss: 0.7307 - val_acc: 0.7086\n",
      "Epoch 4/50\n",
      "19800/19800 [==============================] - 17s 874us/step - loss: 0.0941 - acc: 0.9684 - val_loss: 0.7988 - val_acc: 0.6726\n",
      "Epoch 5/50\n",
      "19800/19800 [==============================] - 17s 871us/step - loss: 0.0822 - acc: 0.9728 - val_loss: 0.8115 - val_acc: 0.6712\n",
      "Epoch 6/50\n",
      "19800/19800 [==============================] - 17s 874us/step - loss: 0.0747 - acc: 0.9754 - val_loss: 0.8158 - val_acc: 0.6759\n",
      "Epoch 7/50\n",
      "19800/19800 [==============================] - 18s 885us/step - loss: 0.0722 - acc: 0.9759 - val_loss: 0.7902 - val_acc: 0.6823\n",
      "Epoch 8/50\n",
      "19800/19800 [==============================] - 18s 891us/step - loss: 0.0671 - acc: 0.9777 - val_loss: 0.8144 - val_acc: 0.6841\n",
      "Epoch 9/50\n",
      "19800/19800 [==============================] - 17s 871us/step - loss: 0.0639 - acc: 0.9784 - val_loss: 0.7975 - val_acc: 0.6856\n",
      "Epoch 10/50\n",
      "19800/19800 [==============================] - 17s 872us/step - loss: 0.0633 - acc: 0.9783 - val_loss: 0.8061 - val_acc: 0.6909\n",
      "Epoch 11/50\n",
      "19800/19800 [==============================] - 18s 893us/step - loss: 0.0592 - acc: 0.9801 - val_loss: 0.7728 - val_acc: 0.6744\n",
      "Epoch 12/50\n",
      "19800/19800 [==============================] - 18s 893us/step - loss: 0.0594 - acc: 0.9793 - val_loss: 0.7878 - val_acc: 0.6783\n",
      "Epoch 13/50\n",
      "19800/19800 [==============================] - 18s 887us/step - loss: 0.0568 - acc: 0.9805 - val_loss: 0.7442 - val_acc: 0.6791\n",
      "Epoch 14/50\n",
      "19800/19800 [==============================] - 18s 900us/step - loss: 0.0564 - acc: 0.9808 - val_loss: 0.7065 - val_acc: 0.6899\n",
      "Epoch 15/50\n",
      "19800/19800 [==============================] - 18s 895us/step - loss: 0.0531 - acc: 0.9817 - val_loss: 0.7164 - val_acc: 0.6788\n",
      "Epoch 16/50\n",
      "19800/19800 [==============================] - 18s 903us/step - loss: 0.0533 - acc: 0.9818 - val_loss: 0.7045 - val_acc: 0.7258\n",
      "Epoch 17/50\n",
      "19800/19800 [==============================] - 18s 884us/step - loss: 0.0513 - acc: 0.9823 - val_loss: 0.7099 - val_acc: 0.6784\n",
      "Epoch 18/50\n",
      "19800/19800 [==============================] - 18s 891us/step - loss: 0.0493 - acc: 0.9831 - val_loss: 0.7094 - val_acc: 0.6798\n",
      "Epoch 19/50\n",
      "19800/19800 [==============================] - 17s 884us/step - loss: 0.0491 - acc: 0.9830 - val_loss: 0.7383 - val_acc: 0.6773\n",
      "Epoch 20/50\n",
      "19800/19800 [==============================] - 18s 890us/step - loss: 0.0478 - acc: 0.9826 - val_loss: 0.7455 - val_acc: 0.6816\n",
      "Epoch 21/50\n",
      "19800/19800 [==============================] - 18s 887us/step - loss: 0.0478 - acc: 0.9826 - val_loss: 0.7216 - val_acc: 0.6786\n",
      "Epoch 22/50\n",
      "19800/19800 [==============================] - 18s 891us/step - loss: 0.0448 - acc: 0.9838 - val_loss: 0.7570 - val_acc: 0.6825\n",
      "Epoch 23/50\n",
      "19800/19800 [==============================] - 18s 895us/step - loss: 0.0441 - acc: 0.9843 - val_loss: 0.7411 - val_acc: 0.6758\n",
      "Epoch 24/50\n",
      "19800/19800 [==============================] - 18s 892us/step - loss: 0.0417 - acc: 0.9854 - val_loss: 0.7563 - val_acc: 0.6792\n",
      "Epoch 25/50\n",
      "19800/19800 [==============================] - 17s 877us/step - loss: 0.0434 - acc: 0.9844 - val_loss: 0.7615 - val_acc: 0.6804\n",
      "Epoch 26/50\n",
      "19800/19800 [==============================] - 17s 862us/step - loss: 0.0418 - acc: 0.9857 - val_loss: 0.8043 - val_acc: 0.6796\n",
      "Epoch 27/50\n",
      "19800/19800 [==============================] - 17s 868us/step - loss: 0.0399 - acc: 0.9851 - val_loss: 0.7810 - val_acc: 0.6805\n",
      "Epoch 28/50\n",
      "19800/19800 [==============================] - 18s 895us/step - loss: 0.0389 - acc: 0.9852 - val_loss: 0.7935 - val_acc: 0.6764\n",
      "Epoch 29/50\n",
      "19800/19800 [==============================] - 18s 885us/step - loss: 0.0384 - acc: 0.9854 - val_loss: 0.9674 - val_acc: 0.5110\n",
      "Epoch 30/50\n",
      "19800/19800 [==============================] - 17s 876us/step - loss: 0.0371 - acc: 0.9854 - val_loss: 0.9754 - val_acc: 0.5155\n",
      "Epoch 31/50\n",
      "19800/19800 [==============================] - 17s 873us/step - loss: 0.0371 - acc: 0.9856 - val_loss: 0.9290 - val_acc: 0.5140\n",
      "Epoch 32/50\n",
      "19800/19800 [==============================] - 18s 899us/step - loss: 0.0359 - acc: 0.9864 - val_loss: 1.1191 - val_acc: 0.5090\n",
      "Epoch 33/50\n",
      "19800/19800 [==============================] - 18s 889us/step - loss: 0.0365 - acc: 0.9860 - val_loss: 1.0507 - val_acc: 0.5129\n",
      "Epoch 34/50\n",
      "19800/19800 [==============================] - 18s 894us/step - loss: 0.0357 - acc: 0.9865 - val_loss: 0.9941 - val_acc: 0.5155\n",
      "Epoch 35/50\n",
      "19800/19800 [==============================] - 18s 902us/step - loss: 0.0338 - acc: 0.9872 - val_loss: 0.9185 - val_acc: 0.5949\n",
      "Epoch 36/50\n",
      "19800/19800 [==============================] - 18s 914us/step - loss: 0.0330 - acc: 0.9870 - val_loss: 1.0163 - val_acc: 0.5175\n",
      "Epoch 37/50\n",
      "19800/19800 [==============================] - 18s 910us/step - loss: 0.0325 - acc: 0.9878 - val_loss: 1.0741 - val_acc: 0.5122\n",
      "Epoch 38/50\n",
      "19800/19800 [==============================] - 18s 902us/step - loss: 0.0325 - acc: 0.9879 - val_loss: 1.1516 - val_acc: 0.5133\n",
      "Epoch 39/50\n",
      "19800/19800 [==============================] - 18s 892us/step - loss: 0.0333 - acc: 0.9875 - val_loss: 1.1243 - val_acc: 0.4939\n",
      "Epoch 40/50\n",
      "19800/19800 [==============================] - 18s 890us/step - loss: 0.0308 - acc: 0.9888 - val_loss: 1.1803 - val_acc: 0.5112\n",
      "Epoch 41/50\n",
      "19800/19800 [==============================] - 18s 895us/step - loss: 0.0298 - acc: 0.9879 - val_loss: 1.2873 - val_acc: 0.4872\n",
      "Epoch 42/50\n",
      "19800/19800 [==============================] - 18s 892us/step - loss: 0.0297 - acc: 0.9893 - val_loss: 1.2253 - val_acc: 0.5126\n",
      "Epoch 43/50\n",
      "19800/19800 [==============================] - 18s 906us/step - loss: 0.0295 - acc: 0.9886 - val_loss: 1.2521 - val_acc: 0.5154\n",
      "Epoch 44/50\n",
      "19800/19800 [==============================] - 17s 879us/step - loss: 0.0310 - acc: 0.9886 - val_loss: 1.2391 - val_acc: 0.4842\n",
      "Epoch 45/50\n",
      "19800/19800 [==============================] - 17s 883us/step - loss: 0.0279 - acc: 0.9898 - val_loss: 1.3029 - val_acc: 0.4848\n",
      "Epoch 46/50\n",
      "19800/19800 [==============================] - 17s 878us/step - loss: 0.0280 - acc: 0.9891 - val_loss: 1.2801 - val_acc: 0.5124\n",
      "Epoch 47/50\n",
      "19800/19800 [==============================] - 18s 903us/step - loss: 0.0290 - acc: 0.9890 - val_loss: 1.3848 - val_acc: 0.4808\n",
      "Epoch 48/50\n",
      "19800/19800 [==============================] - 18s 890us/step - loss: 0.0279 - acc: 0.9897 - val_loss: 1.3957 - val_acc: 0.4805\n",
      "Epoch 49/50\n",
      "19800/19800 [==============================] - 18s 891us/step - loss: 0.0266 - acc: 0.9899 - val_loss: 1.3877 - val_acc: 0.4823\n",
      "Epoch 50/50\n",
      "19800/19800 [==============================] - 17s 879us/step - loss: 0.0274 - acc: 0.9897 - val_loss: 1.4275 - val_acc: 0.4863\n",
      "Time taken for training:  880.8676347732544\n"
     ]
    }
   ],
   "source": [
    "n_most_common_words = 1000 #150 \n",
    "model = Sequential()\n",
    "# n_most_common_words=Size of the vocabulary, emb_dim=Dimension of the dense embedding, input_length=Length of input sequences, when it is constant\n",
    "model.add(Embedding(n_most_common_words, emb_dim, input_length=X_train_res.shape[1]))\n",
    "model.add(SpatialDropout1D(0.55))\n",
    "model.add(LSTM(16, dropout=0.55, recurrent_dropout=0.55))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "# Downsampled and balanced dataset\n",
    "# history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.0,callbacks=[EarlyStopping(monitor='loss',patience=7, min_delta=0.0001)])\n",
    "\n",
    "\n",
    "history = model.fit(X_train_res, ytrainres_cat, epochs=epochs, batch_size=batch_size, validation_split=0.0, validation_data=(X_val_res, yvalres_cat),callbacks=[EarlyStopping(monitor='loss',patience=7, min_delta=0.0001)])\n",
    "\n",
    "\n",
    "# history = model.fit(add_greedy_X, add_greedy_y, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=7, min_delta=0.0001)])\n",
    "\n",
    "# # Entire and unbalanced dataset\n",
    "# history = model.fit(under_sample_X, under_sample_y, epochs=epochs, batch_size=batch_size,validation_split=0,callbacks=[EarlyStopping(monitor='val_loss',patience=7, min_delta=0.0001)])\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time taken for training: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and evaluate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6188/6188 [==============================] - 14s 2ms/step\n",
      "Test set\n",
      "  Loss: 1.7165\n",
      "  Accuracy: 0.6335\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test_res, ytestres_cat)\n",
    "print('Test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test_res, batch_size=32, verbose=1)\n",
    "ytest_true = y_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ytest_true = y_test_res\n",
    "# y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Compute the average precision score\n",
    "average_precision = average_precision_score(ytest_true, y_pred)\n",
    "print('Average Precision Score: {:0.4f}\\n'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(ytest_true, y_pred)\n",
    "print(recall[1])\n",
    "print('Recall Score: {:0.4f}\\n'.format(recall[1]))\n",
    "\n",
    "# # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "# step_kwargs = ({'step': 'post'}\n",
    "#                if 'step' in signature(plt.fill_between).parameters\n",
    "#                else {})\n",
    "# plt.step(recall, precision, color='b', alpha=0.2,\n",
    "#          where='post')\n",
    "# plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "#           average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print('Accuracy:', accuracy_score(ytest_true, y_pred))\n",
    "print('Recall:', recall_score(ytest_true, y_pred))\n",
    "print('Precision:', precision_score(ytest_true, y_pred))\n",
    "print('F1 score:', f1_score(ytest_true, y_pred))\n",
    "print('\\n clasification report:\\n', classification_report(ytest_true, y_pred))\n",
    "print('\\n confusion matrix:\\n',confusion_matrix(ytest_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# fig.savefig('clean_train_acc.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig('clean_train_loss.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# # Get the dictionary containing each metric and the loss for each epoch\n",
    "# history_dict = history.history\n",
    "# # Save it under the form of a json file\n",
    "# json.dump(history_dict, open(your_history_path, 'w'))\n",
    "\n",
    "import pickle\n",
    "with open('./saved_model/less_imbal/6k_40k', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "infile = open('./saved_model/cleantrain_final/64_1_best','rb')\n",
    "history0 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to models folder \n",
    "model.save('./saved_model/less_imbal/'+ '6k_40k' + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading previously saved model\n",
    "from keras.models import load_model\n",
    "model = load_model('./saved_model/less_imbal2/'+'9x_450k.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving variables and df pickle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "norm_test.to_pickle('./saved_model/upsample/'+ 'norm_testk' + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train = pd.read_pickle('./saved_model/less_imbal2/'+ 'norm_train9x_450k' + '.pkl')\n",
    "norm_test = pd.read_pickle('./saved_model/less_imbal2/'+ 'norm_test9x_450k' + '.pkl')\n",
    "print(pd.value_counts(norm_train['CATEGORY']))\n",
    "print(pd.value_counts(norm_test['CATEGORY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_test = norm_test[:3000]\n",
    "num_tr = 10000\n",
    "norm_train = norm_train.sample(num_tr, random_state=9, replace=False)\n",
    "norm_test = norm_test.sample(num_tr, random_state=9, replace=False)\n",
    "\n",
    "# trialset = pd.concat([ss,pp,gg,ssp,norm_test], ignore_index=True)\n",
    "# trialset = pd.concat([ss,pp,gg,ssp], ignore_index=True)\n",
    "trtrainset = pd.concat([norm_train], ignore_index=True)\n",
    "trtrainset = trtrainset.sample(frac=1, random_state=39, replace=False)\n",
    "trtestset = pd.concat([norm_test], ignore_index=True)\n",
    "trtestset = trtestset.sample(frac=1, random_state=39, replace=False)\n",
    "\n",
    "# label(trialset)\n",
    "# pd.value_counts(trialset['LABEL'])\n",
    "# trialpred = model.predict(preprocess(trialset), verbose=1)\n",
    "# plt.hist(trialpred[:,0], range=(0,1))\n",
    "\n",
    "X_trtrain, y_trtrain = dftoXY(trtrainset) #.iloc[:3000]\n",
    "trtrain_accr = model.evaluate(X_trtrain,y_trtrain)\n",
    "print('Tr train set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(trtrain_accr[0],trtrain_accr[1]))\n",
    "\n",
    "X_trtest, y_trtest = dftoXY(trtestset) #.iloc[:3000]\n",
    "trtest_accr = model.evaluate(X_trtest,y_trtest)\n",
    "print('Tr test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(trtest_accr[0],trtest_accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = pd.concat([s,p,g,sp], ignore_index=True)\n",
    "positives = positives.sample(frac=1, random_state=39, replace=False)\n",
    "\n",
    "X_pos, y_pos = dftoXY(positives) \n",
    "pos_accr = model.evaluate(X_pos,y_pos)\n",
    "print('Tr train set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(pos_accr[0],pos_accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label(norm_test)\n",
    "pd.value_counts(norm_test['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_neg, y_neg = dftoXY(norm_test) #.iloc[:3000]\n",
    "neg_accr = model.evaluate(X_neg,y_neg)\n",
    "print('Test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(neg_accr[0],neg_accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = norm_test\n",
    "negtest = preprocess(ntest.iloc[1000:2000])\n",
    "negt = model.predict(negtest, verbose=1)\n",
    "plt.hist(negt[:,0], range=(0,1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predtest_neg = np.count_nonzero(negt[:,0] >= 0.5)\n",
    "print(predtest_neg)\n",
    "predtest_accr = predtest_neg / len(negt)\n",
    "print('Test set\\n Accuracy: {:0.4f}'.format(predtest_accr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All test FPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Loading and reading csv input data \n",
    "\n",
    "# all_testset = 'clean_test_allFP_noDups.csv'\n",
    "leakFP = 'clean_test_leakFP_noDups.csv'\n",
    "suicidalFP = 'clean_test_suicidalFP_noDups.csv'\n",
    "greedyFP = 'clean_test_greedyFP_noDups.csv'\n",
    "\n",
    "leakFP_test = pd.read_csv('./input_data/final/no_duplicates/'+leakFP, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "suicidalFP_test = pd.read_csv('./input_data/final/no_duplicates/'+suicidalFP, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "greedyFP_test = pd.read_csv('./input_data/final/no_duplicates/'+greedyFP, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "\n",
    "# leakFP_test.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "X_leakFP, y_leakFP = dftoXY(leakFP_test)\n",
    "leakFP_accr = model.evaluate(X_leakFP,y_leakFP)\n",
    "print('Leak test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(leakFP_accr[0],leakFP_accr[1]))\n",
    "\n",
    "X_suicidalFP, y_suicidalFP = dftoXY(suicidalFP_test)\n",
    "suicidalFP_accr = model.evaluate(X_suicidalFP,y_suicidalFP)\n",
    "print('Suicidal test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(suicidalFP_accr[0],suicidalFP_accr[1]))\n",
    "\n",
    "X_greedyFP, y_greedyFP = dftoXY(greedyFP_test)\n",
    "greedyFP_accr = model.evaluate(X_greedyFP,y_greedyFP)\n",
    "print('Greedy test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(greedyFP_accr[0],greedyFP_accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_leakFP, y_leakFP = dftoXY(test_leakFPs)\n",
    "leakFP_accr = model.evaluate(X_leakFP,y_leakFP)\n",
    "print('Leak test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(leakFP_accr[0],leakFP_accr[1]))\n",
    "\n",
    "X_suicidalFP, y_suicidalFP = dftoXY(test_suicidalFPs)\n",
    "suicidalFP_accr = model.evaluate(X_suicidalFP,y_suicidalFP)\n",
    "print('Suicidal test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(suicidalFP_accr[0],suicidalFP_accr[1]))\n",
    "\n",
    "X_greedyFP, y_greedyFP = dftoXY(test_lockFPs)\n",
    "greedyFP_accr = model.evaluate(X_greedyFP,y_greedyFP)\n",
    "print('Greedy test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(greedyFP_accr[0],greedyFP_accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP = 'clean_test_greedyFP_noDups.csv'\n",
    "# FP = 'clean_test_leakFP_noDups.csv'\n",
    "FP = 'clean_test_suicidalFP_noDups.csv'\n",
    "\n",
    "all_test = pd.read_csv('./input_data/final/no_duplicates/'+ FP, usecols=['ADDRESS', 'OPCODE', 'CATEGORY'])\n",
    "\n",
    "all_X = preprocess(all_test)\n",
    "pred_all = model.predict(all_X, verbose=1)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(pred_all[:,1])\n",
    "plt.xlabel('Prediction (0.0 = Not vulnerable, 1.0 = Vulnerable)')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Distribution of LSTM Prediction on All FPs')\n",
    "# plt.legend()\n",
    "# fig.savefig('./figures/AllFP_distr.png',dpi=300)\n",
    "\n",
    "predall_pos = np.count_nonzero(pred_all[:,1] < 0.5)\n",
    "print(predall_pos)\n",
    "predall_accr = predall_pos / len(pred_all)\n",
    "print('Test set\\n Accuracy: {:0.4f}'.format(predall_accr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "infile = open('./saved_model/less_imbal2/' + '15x_750k','rb')\n",
    "history0 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history0['acc']\n",
    "val_acc = history0['val_acc']\n",
    "loss = history0['loss']\n",
    "val_loss = history0['val_loss']\n",
    "\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "fig.savefig('./figures/clean_train_acc.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('./figures/clean_train_loss.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting and saving flagged negatives for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_neg = model.predict(X_trtest, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predneg = np.count_nonzero(pred_neg[:,1] > 0.5)\n",
    "predneg_accr = predneg / len(pred_neg)\n",
    "print('Percentage of Negatives Flagged: {:0.4f}'.format(predneg_accr))\n",
    "\n",
    "LSTM_pos = np.nonzero(pred_neg[:,1] > 0.5)\n",
    "np.array(np.nonzero(pred_neg[:,1] > 0.5)).shape\n",
    "\n",
    "lstm_Negflagged = norm_test.iloc[LSTM_pos]\n",
    "# lstm_Negflagged.to_csv ('./output_data/lstm_flaggedNeg_final.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.hist(pred_neg[:,1])\n",
    "plt.xlabel('Prediction (less than 0.5 (Not vulnerable), greater than 0.5 (Vulnerable))')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Distribution of LSTM Prediction on Unflagged Contracts')\n",
    "\n",
    "fig.savefig('./figures/lstm_flaggedNeg_final.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"v3_550KLSTM64epoch100train0.64drop0.55\"\n",
    "\n",
    "# \"v3_550KLSTM64epoch100train0.64drop0.5\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save model to models folder \n",
    "model.save('./saved_model/less_imbal/'+ '6k_40k' + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading previously saved model\n",
    "from keras.models import load_model\n",
    "# model = load_model('./saved_model/less_imbal2/'+'9x_450k.h5')\n",
    "model = load_model('./saved_model/postreviewV3/'+ 'train' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_CE7454",
   "language": "python",
   "name": "dl_ce7454"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
